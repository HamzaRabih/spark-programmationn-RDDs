
#   Spark â€” git init



## ðŸ“Œ EnoncÃ©
Ce TP a pour objectif de manipuler **Apache Spark** afin de rÃ©aliser un traitement parallÃ¨le et distribuÃ© sur un fichier de ventes.  
On cherche Ã  dÃ©velopper deux applications Spark en **Java** :

1. **Exercice 1 :**
   - Ã€ partir dâ€™un fichier texte `ventes.txt`, contenant les ventes dâ€™une entreprise dans diffÃ©rentes villes, dÃ©terminer le **total des ventes par ville**.
   - La structure du fichier `ventes.txt` est la suivante :
     ```
     date ville produit prix
     ```
     Exemple :
     ```
     27/01/2025 Tangier AsusZenBook 5950
     10/02/2024 Tangier HPEnvy 6126
     ```

2. **Exercice 2 :**
   - CrÃ©er une deuxiÃ¨me application permettant de calculer le **prix total des ventes par ville et par annÃ©e**.

---
## ðŸ’¡  Technologies utilisÃ©es

- **Java 8**
- **Apache Spark 3.3+**
- **Maven**
- **Docker & Docker Compose**
- **Bitnami Spark Docker image**

---
## ðŸ“‚ Structure du projet
```
TP_Spark/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/java/Main.java
â”œâ”€â”€ ventes.txt
â”œâ”€â”€ pom.xml
â””â”€â”€ target/TP_Spark-1.0-SNAPSHOT.jar
```

---


## ðŸš€ ExÃ©cution locale (test)

ðŸ“¸ Exercice 1 :

![Terminal output](images/local.png)

---

##  ExÃ©cution sur un cluster Spark  Docker

### ðŸ”§ 1. Arborescence recommandÃ©e

```
spark-cluster/
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ app/
    â”œâ”€â”€ TP_Spark-1.0-SNAPSHOT.jar
    â””â”€â”€ ventes.txt
```

### â–¶ï¸ 2. Lancer le cluster

```bash
docker-compose up -d
```

ðŸ‘€ Interface Spark : [http://localhost:8080](http://localhost:8080)

---

### ðŸ“¤ 3. ExÃ©cuter l'application

```bash
spark-submit --class Main --master spark://spark-master:7077 /app/TP_Spark-1.0-SNAPSHOT.jar

```

---

## ðŸ“¸ RÃ©sultats dans le cluster Spark

ðŸ“Œ le prix total des ventes des produits par ville et par annÃ©e.

**ExÃ©cution visible dans Docker Desktop > spark-master > Exec :**


![](images/cluster.png) 

---
## ðŸ“Œ Auteur
Hamza Rabih â€“ TP Big Data- Spark -Master 1 II-BDCC â€“ ENSET